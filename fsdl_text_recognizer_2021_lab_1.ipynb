{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fsdl-text-recognizer-2021-lab-1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM5Q4fTTo+OMRIP853/vojI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/razormin/razormin/blob/main/fsdl_text_recognizer_2021_lab_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wL0-QrKtIgL",
        "outputId": "11048bfe-1b1c-4a63-8b15-5ed2ef9d2ff3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun Jul 18 22:15:59 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.42.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlRXTT2WtQgA",
        "outputId": "87f91f0e-a12c-4c89-e89d-1bb4298aa9a1"
      },
      "source": [
        "# FSDL Spring 2021 Setup\n",
        "!git clone https://github.com/full-stack-deep-learning/fsdl-text-recognizer-2021-labs\n",
        "%cd fsdl-text-recognizer-2021-labs\n",
        "!pip3 install boltons wandb pytorch_lightning==1.1.4 pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 torchtext==0.8.1 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'fsdl-text-recognizer-2021-labs'...\n",
            "remote: Enumerating objects: 798, done.\u001b[K\n",
            "remote: Counting objects: 100% (230/230), done.\u001b[K\n",
            "remote: Compressing objects: 100% (88/88), done.\u001b[K\n",
            "remote: Total 798 (delta 162), reused 143 (delta 142), pack-reused 568\u001b[K\n",
            "Receiving objects: 100% (798/798), 18.88 MiB | 22.72 MiB/s, done.\n",
            "Resolving deltas: 100% (400/400), done.\n",
            "/fsdl-text-recognizer-2021-labs\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting boltons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/a7/1a31561d10a089fcb46fe286766dd4e053a12f6e23b4fd1c26478aff2475/boltons-21.0.0-py2.py3-none-any.whl (193kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 9.2MB/s \n",
            "\u001b[?25hCollecting wandb\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/eb/cb124dd42e205a2d5fd832add322292a731580acb5bce3a0daf423de5f02/wandb-0.11.0-py2.py3-none-any.whl (1.8MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8MB 42.7MB/s \n",
            "\u001b[?25hCollecting pytorch_lightning==1.1.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/12/98/86a89dcd54f84582bbf24cb29cd104b966fcf934d92d5dfc626f225015d2/pytorch_lightning-1.1.4-py3-none-any.whl (684kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 53.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: pip in /usr/local/lib/python3.7/dist-packages (19.3.1)\n",
            "Requirement already satisfied: install in /usr/local/lib/python3.7/dist-packages (1.3.4)\n",
            "Collecting torch==1.7.1+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torch-1.7.1%2Bcu110-cp37-cp37m-linux_x86_64.whl (1156.8MB)\n",
            "\u001b[K     |███████████████████████         | 834.1MB 1.4MB/s eta 0:03:49tcmalloc: large alloc 1147494400 bytes == 0x55f8ea45c000 @  0x7efdb2bad615 0x55f8b022302c 0x55f8b030317a 0x55f8b0225e4d 0x55f8b0317c0d 0x55f8b029a0d8 0x55f8b0294c35 0x55f8b022773a 0x55f8b0299f40 0x55f8b0294c35 0x55f8b022773a 0x55f8b029693b 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b039a0d1 0x55f8b02fb2f9 0x55f8b0265ac4 0x55f8b02268a9 0x55f8b029ab0a 0x55f8b022765a 0x55f8b0295b0e 0x55f8b0295235 0x55f8b022773a 0x55f8b0295b0e 0x55f8b022765a 0x55f8b0295b0e\n",
            "\u001b[K     |█████████████████████████████▏  | 1055.7MB 1.2MB/s eta 0:01:22tcmalloc: large alloc 1434370048 bytes == 0x55f92eab2000 @  0x7efdb2bad615 0x55f8b022302c 0x55f8b030317a 0x55f8b0225e4d 0x55f8b0317c0d 0x55f8b029a0d8 0x55f8b0294c35 0x55f8b022773a 0x55f8b0299f40 0x55f8b0294c35 0x55f8b022773a 0x55f8b029693b 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b0295fb3 0x55f8b0318a56 0x55f8b039a0d1 0x55f8b02fb2f9 0x55f8b0265ac4 0x55f8b02268a9 0x55f8b029ab0a 0x55f8b022765a 0x55f8b0295b0e 0x55f8b0295235 0x55f8b022773a 0x55f8b0295b0e 0x55f8b022765a 0x55f8b0295b0e\n",
            "\u001b[K     |████████████████████████████████| 1156.7MB 1.4MB/s eta 0:00:01tcmalloc: large alloc 1445945344 bytes == 0x55f98429e000 @  0x7efdb2bad615 0x55f8b022302c 0x55f8b030317a 0x55f8b0225e4d 0x55f8b0317c0d 0x55f8b029a0d8 0x55f8b0294c35 0x55f8b022773a 0x55f8b0295d67 0x55f8b0294c35 0x55f8b022773a 0x55f8b0295d67 0x55f8b0294c35 0x55f8b022773a 0x55f8b0295d67 0x55f8b0294c35 0x55f8b022773a 0x55f8b0295d67 0x55f8b0294c35 0x55f8b022773a 0x55f8b0295d67 0x55f8b022765a 0x55f8b0295d67 0x55f8b0294c35 0x55f8b022773a 0x55f8b029693b 0x55f8b0294c35 0x55f8b022773a 0x55f8b029693b 0x55f8b0294c35 0x55f8b0227dd1\n",
            "\u001b[K     |████████████████████████████████| 1156.8MB 15kB/s \n",
            "\u001b[?25hCollecting torchvision==0.8.2+cu110\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu110/torchvision-0.8.2%2Bcu110-cp37-cp37m-linux_x86_64.whl (12.9MB)\n",
            "\u001b[K     |████████████████████████████████| 12.9MB 164kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.7.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/37/16/ecdb9eb09ec6b8133d6c9536ea9e49cd13c9b5873c8488b8b765a39028da/torchaudio-0.7.2-cp37-cp37m-manylinux1_x86_64.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 50.9MB/s \n",
            "\u001b[?25hCollecting torchtext==0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/80/046f0691b296e755ae884df3ca98033cb9afcaf287603b2b7999e94640b8/torchtext-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (7.0MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0MB 47.6MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.1)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 12.0MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting urllib3>=1.26.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5f/64/43575537846896abac0b15c3e5ac678d787a4021e906703f1766bfb8ea11/urllib3-1.26.6-py2.py3-none-any.whl (138kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 47.2MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/fd/01/ff260a18caaf4457eb028c96eeb405c4a230ca06c8ec9c1379f813caa52e/configparser-5.0.2-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/41/75fad31fff378871c462745ce724b3701a6acad17028d79476ec2545e40f/sentry_sdk-1.3.0-py2.py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 48.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Collecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/91/b38c4fabb6e5092ab23492ded4f318ab7299b19263272b703478038c0fbc/GitPython-3.1.18-py3-none-any.whl (170kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 53.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (1.19.5)\n",
            "Collecting fsspec[http]>=0.8.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/e1/7111d8afc76ee3171f4f99592cd29bac9d233ae1aa34623011506f955434/fsspec-2021.7.0-py3-none-any.whl (118kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 58.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (2.5.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.1.4) (4.41.1)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 43.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.7.1+cu110) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.8.2+cu110) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from sentry-sdk>=0.4.0->wandb) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/e8/f414d1a4f0bbc668ed441f74f44c116d9816833a48bf81d22b697090dba8/gitdb-4.0.7-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n",
            "\u001b[?25hCollecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 47.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.34.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.32.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.12.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.36.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.3.4)\n",
            "Collecting smmap<5,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/68/ee/d540eb5e5996eb81c26ceffac6ee49041d473bc5125f2aa995cf51ec1cf1/smmap-4.0.0-py2.py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 55.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=0.8.1->pytorch_lightning==1.1.4) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 47.7MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (4.6.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning==1.1.4) (3.5.0)\n",
            "Building wheels for collected packages: subprocess32, pathtools, future\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp37-none-any.whl size=6502 sha256=ccbd82492d62f1e14221aa329d96db549923e83cb6e61f122bc8b67f64b37c1b\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp37-none-any.whl size=8807 sha256=e96ddcd41c55ef33a7c15ac50ded6d3d4dacb5b8bd441c8e4f1f4740697e8e6b\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=f3d28dc94f6a8d48a7b5e69cb5ee8e529e6df71ae1393000ffd36502925ae30b\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built subprocess32 pathtools future\n",
            "\u001b[31mERROR: requests 2.23.0 has requirement urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you'll have urllib3 1.26.6 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: pytorch-lightning 1.1.4 has requirement PyYAML>=5.1, but you'll have pyyaml 3.13 which is incompatible.\u001b[0m\n",
            "Installing collected packages: boltons, shortuuid, docker-pycreds, subprocess32, pathtools, urllib3, configparser, sentry-sdk, smmap, gitdb, GitPython, wandb, torch, multidict, yarl, async-timeout, aiohttp, fsspec, future, pytorch-lightning, torchvision, torchaudio, torchtext\n",
            "  Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "Successfully installed GitPython-3.1.18 aiohttp-3.7.4.post0 async-timeout-3.0.1 boltons-21.0.0 configparser-5.0.2 docker-pycreds-0.4.0 fsspec-2021.7.0 future-0.18.2 gitdb-4.0.7 multidict-5.1.0 pathtools-0.1.2 pytorch-lightning-1.1.4 sentry-sdk-1.3.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 torch-1.7.1+cu110 torchaudio-0.7.2 torchtext-0.8.1 torchvision-0.8.2+cu110 urllib3-1.26.6 wandb-0.11.0 yarl-1.6.3\n",
            "env: PYTHONPATH=.:$PYTHONPATH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qLyzyY__u0t9",
        "outputId": "86ac595c-3624-40d3-ef48-58267e3f2e6c"
      },
      "source": [
        "cd lab1"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/fsdl-text-recognizer-2021-labs/lab1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_M9AeXF_u276",
        "outputId": "210e4245-c270-48ea-ba83-bd0997d0714a"
      },
      "source": [
        "!python training/run_experiment.py --max_epochs=3"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [03:32, 56761.76it/s]                 Extracting /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-images-idx3-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "32768it [00:00, 135994.02it/s]\n",
            "Extracting /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/train-labels-idx1-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\n",
            "  0% 0/1648877 [00:00<?, ?it/s]\u001b[A\n",
            "  1% 16384/1648877 [00:00<00:12, 130536.94it/s]\u001b[A\n",
            "  1% 24576/1648877 [00:00<00:16, 99129.39it/s] \u001b[A\n",
            "  2% 32768/1648877 [00:00<00:19, 84983.24it/s]\u001b[A\n",
            "  2% 40960/1648877 [00:00<00:20, 79368.63it/s]\u001b[A\n",
            "  3% 49152/1648877 [00:00<00:21, 74614.65it/s]\u001b[A\n",
            "  3% 57344/1648877 [00:00<00:22, 70900.89it/s]\u001b[A\n",
            "  4% 65536/1648877 [00:01<00:23, 68700.22it/s]\u001b[A\n",
            "  4% 73728/1648877 [00:01<00:23, 67132.78it/s]\u001b[A\n",
            "  5% 81920/1648877 [00:01<00:23, 66158.64it/s]\u001b[A\n",
            "  5% 90112/1648877 [00:01<00:23, 65436.04it/s]\u001b[A\n",
            "  6% 98304/1648877 [00:01<00:23, 64939.09it/s]\u001b[A\n",
            "  6% 106496/1648877 [00:01<00:24, 64025.95it/s]\u001b[A\n",
            "  7% 114688/1648877 [00:01<00:23, 64247.09it/s]\u001b[A\n",
            "  7% 122880/1648877 [00:01<00:23, 64392.88it/s]\u001b[A\n",
            "  8% 131072/1648877 [00:02<00:23, 64234.42it/s]\u001b[A\n",
            "  8% 139264/1648877 [00:02<00:23, 63637.70it/s]\u001b[A\n",
            "  9% 147456/1648877 [00:02<00:23, 64117.56it/s]\u001b[A\n",
            "  9% 155648/1648877 [00:02<00:23, 64035.16it/s]\u001b[A\n",
            " 10% 163840/1648877 [00:02<00:23, 63352.75it/s]\u001b[A\n",
            " 10% 172032/1648877 [00:02<00:23, 64134.27it/s]\u001b[A\n",
            " 11% 180224/1648877 [00:02<00:23, 63415.15it/s]\u001b[A\n",
            " 11% 188416/1648877 [00:02<00:22, 64077.15it/s]\u001b[A\n",
            " 12% 196608/1648877 [00:03<00:22, 64099.08it/s]\u001b[A\n",
            " 12% 204800/1648877 [00:03<00:22, 64053.41it/s]\u001b[A\n",
            " 13% 212992/1648877 [00:03<00:22, 63902.04it/s]\u001b[A\n",
            " 13% 221184/1648877 [00:03<00:22, 63644.27it/s]\u001b[A\n",
            " 14% 229376/1648877 [00:03<00:22, 63991.85it/s]\u001b[A\n",
            " 14% 237568/1648877 [00:03<00:22, 63930.35it/s]\u001b[A\n",
            " 15% 245760/1648877 [00:03<00:21, 63907.44it/s]\u001b[A\n",
            " 15% 253952/1648877 [00:04<00:21, 63721.75it/s]\u001b[A\n",
            " 16% 262144/1648877 [00:04<00:21, 63659.81it/s]\u001b[A\n",
            " 16% 270336/1648877 [00:04<00:21, 63971.93it/s]\u001b[A\n",
            " 17% 278528/1648877 [00:04<00:21, 63081.02it/s]\u001b[A\n",
            " 17% 286720/1648877 [00:04<00:21, 64143.92it/s]\u001b[A\n",
            " 18% 294912/1648877 [00:04<00:21, 63900.86it/s]\u001b[A\n",
            " 18% 303104/1648877 [00:04<00:21, 64017.01it/s]\u001b[A\n",
            " 19% 311296/1648877 [00:04<00:20, 63900.65it/s]\u001b[A\n",
            " 19% 319488/1648877 [00:05<00:20, 63978.45it/s]\u001b[A\n",
            " 20% 327680/1648877 [00:05<00:20, 63895.49it/s]\u001b[A\n",
            " 20% 335872/1648877 [00:05<00:20, 63880.21it/s]\u001b[A\n",
            " 21% 344064/1648877 [00:05<00:20, 63846.47it/s]\u001b[A\n",
            " 21% 352256/1648877 [00:05<00:20, 63888.85it/s]\u001b[A\n",
            " 22% 360448/1648877 [00:05<00:20, 63859.82it/s]\u001b[A\n",
            " 22% 368640/1648877 [00:05<00:20, 63809.99it/s]\u001b[A\n",
            " 23% 376832/1648877 [00:05<00:19, 63847.93it/s]\u001b[A\n",
            " 23% 385024/1648877 [00:06<00:20, 62863.66it/s]\u001b[A\n",
            " 24% 393216/1648877 [00:06<00:19, 64147.35it/s]\u001b[A\n",
            " 24% 401408/1648877 [00:06<00:19, 64060.26it/s]\u001b[A\n",
            " 25% 409600/1648877 [00:06<00:19, 63973.38it/s]\u001b[A\n",
            " 25% 417792/1648877 [00:06<00:19, 63872.35it/s]\u001b[A\n",
            " 26% 425984/1648877 [00:06<00:19, 63873.81it/s]\u001b[A\n",
            " 26% 434176/1648877 [00:06<00:19, 63881.49it/s]\u001b[A\n",
            " 27% 442368/1648877 [00:06<00:18, 63853.39it/s]\u001b[A\n",
            " 27% 450560/1648877 [00:07<00:18, 63882.29it/s]\u001b[A\n",
            " 28% 458752/1648877 [00:07<00:18, 63860.11it/s]\u001b[A\n",
            " 28% 466944/1648877 [00:07<00:18, 63480.25it/s]\u001b[A\n",
            " 29% 475136/1648877 [00:07<00:18, 63977.95it/s]\u001b[A\n",
            " 29% 483328/1648877 [00:07<00:18, 63910.73it/s]\u001b[A\n",
            " 30% 491520/1648877 [00:07<00:18, 63796.55it/s]\u001b[A\n",
            " 30% 499712/1648877 [00:07<00:18, 63281.50it/s]\u001b[A\n",
            " 31% 507904/1648877 [00:07<00:17, 64061.59it/s]\u001b[A\n",
            " 31% 516096/1648877 [00:08<00:17, 63991.32it/s]\u001b[A\n",
            " 32% 524288/1648877 [00:08<00:17, 63808.57it/s]\u001b[A\n",
            " 32% 532480/1648877 [00:08<00:17, 63752.97it/s]\u001b[A\n",
            " 33% 540672/1648877 [00:08<00:17, 63598.69it/s]\u001b[A\n",
            " 33% 548864/1648877 [00:08<00:17, 63925.61it/s]\u001b[A\n",
            " 34% 557056/1648877 [00:08<00:17, 63608.13it/s]\u001b[A\n",
            " 34% 565248/1648877 [00:08<00:16, 64095.36it/s]\u001b[A\n",
            " 35% 573440/1648877 [00:09<00:16, 63972.96it/s]\u001b[A\n",
            " 35% 581632/1648877 [00:09<00:16, 63959.88it/s]\u001b[A\n",
            " 36% 589824/1648877 [00:09<00:16, 63536.82it/s]\u001b[A\n",
            " 36% 598016/1648877 [00:09<00:16, 63864.85it/s]\u001b[A\n",
            " 37% 606208/1648877 [00:09<00:16, 63964.04it/s]\u001b[A\n",
            " 37% 614400/1648877 [00:09<00:16, 63686.74it/s]\u001b[A\n",
            " 38% 622592/1648877 [00:09<00:16, 63731.63it/s]\u001b[A\n",
            " 38% 630784/1648877 [00:09<00:15, 63992.56it/s]\u001b[A\n",
            " 39% 638976/1648877 [00:10<00:15, 63959.59it/s]\u001b[A\n",
            " 39% 647168/1648877 [00:10<00:15, 62918.57it/s]\u001b[A\n",
            " 40% 655360/1648877 [00:10<00:15, 64055.51it/s]\u001b[A\n",
            " 40% 663552/1648877 [00:10<00:15, 64111.04it/s]\u001b[A\n",
            " 41% 671744/1648877 [00:10<00:15, 63976.78it/s]\u001b[A\n",
            " 41% 679936/1648877 [00:10<00:15, 63972.20it/s]\u001b[A\n",
            " 42% 688128/1648877 [00:10<00:15, 63950.42it/s]\u001b[A\n",
            " 42% 696320/1648877 [00:10<00:14, 63724.27it/s]\u001b[A\n",
            " 43% 704512/1648877 [00:11<00:14, 63854.33it/s]\u001b[A\n",
            " 43% 712704/1648877 [00:11<00:14, 63911.30it/s]\u001b[A\n",
            " 44% 720896/1648877 [00:11<00:14, 63918.07it/s]\u001b[A\n",
            " 44% 729088/1648877 [00:11<00:14, 63857.99it/s]\u001b[A\n",
            " 45% 737280/1648877 [00:11<00:14, 63796.24it/s]\u001b[A\n",
            " 45% 745472/1648877 [00:11<00:14, 63812.33it/s]\u001b[A\n",
            " 46% 753664/1648877 [00:11<00:14, 63890.06it/s]\u001b[A\n",
            " 46% 761856/1648877 [00:11<00:13, 63877.23it/s]\u001b[A\n",
            " 47% 770048/1648877 [00:12<00:13, 62913.73it/s]\u001b[A\n",
            " 47% 778240/1648877 [00:12<00:13, 64059.73it/s]\u001b[A\n",
            " 48% 786432/1648877 [00:12<00:13, 63938.69it/s]\u001b[A\n",
            " 48% 794624/1648877 [00:12<00:13, 64019.45it/s]\u001b[A\n",
            " 49% 802816/1648877 [00:12<00:13, 63633.42it/s]\u001b[A\n",
            " 49% 811008/1648877 [00:12<00:13, 64013.39it/s]\u001b[A\n",
            " 50% 819200/1648877 [00:12<00:12, 63890.82it/s]\u001b[A\n",
            " 50% 827392/1648877 [00:13<00:12, 63917.65it/s]\u001b[A\n",
            " 51% 835584/1648877 [00:13<00:12, 63903.69it/s]\u001b[A\n",
            " 51% 843776/1648877 [00:13<00:12, 63730.09it/s]\u001b[A\n",
            " 52% 851968/1648877 [00:13<00:12, 63725.86it/s]\u001b[A\n",
            " 52% 860160/1648877 [00:13<00:12, 63810.02it/s]\u001b[A\n",
            " 53% 868352/1648877 [00:13<00:12, 63876.76it/s]\u001b[A\n",
            " 53% 876544/1648877 [00:13<00:12, 63861.72it/s]\u001b[A\n",
            " 54% 884736/1648877 [00:13<00:12, 63670.03it/s]\u001b[A\n",
            " 54% 892928/1648877 [00:14<00:11, 63902.61it/s]\u001b[A\n",
            " 55% 901120/1648877 [00:14<00:11, 63891.28it/s]\u001b[A\n",
            " 55% 909312/1648877 [00:14<00:11, 63844.04it/s]\u001b[A\n",
            " 56% 917504/1648877 [00:14<00:11, 63911.71it/s]\u001b[A\n",
            " 56% 925696/1648877 [00:14<00:11, 63772.41it/s]\u001b[A\n",
            " 57% 933888/1648877 [00:14<00:11, 63888.55it/s]\u001b[A\n",
            " 57% 942080/1648877 [00:14<00:11, 63306.74it/s]\u001b[A\n",
            " 58% 950272/1648877 [00:14<00:10, 64010.90it/s]\u001b[A\n",
            " 58% 958464/1648877 [00:15<00:10, 63791.98it/s]\u001b[A\n",
            " 59% 966656/1648877 [00:15<00:10, 63946.25it/s]\u001b[A\n",
            " 59% 974848/1648877 [00:15<00:10, 63207.46it/s]\u001b[A\n",
            " 60% 983040/1648877 [00:15<00:10, 64089.88it/s]\u001b[A\n",
            " 60% 991232/1648877 [00:15<00:10, 63772.74it/s]\u001b[A\n",
            " 61% 999424/1648877 [00:15<00:10, 63759.93it/s]\u001b[A\n",
            " 61% 1007616/1648877 [00:15<00:10, 63360.23it/s]\u001b[A\n",
            " 62% 1015808/1648877 [00:15<00:09, 64164.21it/s]\u001b[A\n",
            " 62% 1024000/1648877 [00:16<00:09, 64093.76it/s]\u001b[A\n",
            " 63% 1032192/1648877 [00:16<00:09, 64027.06it/s]\u001b[A\n",
            " 63% 1040384/1648877 [00:16<00:09, 66276.63it/s]\u001b[A\n",
            " 64% 1048576/1648877 [00:16<00:09, 65331.80it/s]\u001b[A\n",
            " 64% 1056768/1648877 [00:16<00:09, 65233.14it/s]\u001b[A\n",
            " 65% 1064960/1648877 [00:16<00:09, 62442.83it/s]\u001b[A\n",
            " 65% 1073152/1648877 [00:16<00:09, 60141.35it/s]\u001b[A\n",
            " 66% 1081344/1648877 [00:16<00:09, 61684.62it/s]\u001b[A\n",
            "9920512it [03:50, 56761.76it/s]\n",
            " 67% 1097728/1648877 [00:17<00:09, 60415.72it/s]\u001b[A\n",
            " 67% 1105920/1648877 [00:17<00:09, 59404.23it/s]\u001b[A\n",
            " 68% 1114112/1648877 [00:17<00:09, 56679.68it/s]\u001b[A\n",
            " 68% 1122304/1648877 [00:17<00:09, 54869.43it/s]\u001b[A\n",
            " 69% 1130496/1648877 [00:17<00:09, 55283.90it/s]\u001b[A\n",
            " 69% 1138688/1648877 [00:18<00:09, 55129.46it/s]\u001b[A\n",
            " 70% 1146880/1648877 [00:18<00:08, 56222.63it/s]\u001b[A\n",
            " 70% 1155072/1648877 [00:18<00:08, 56525.19it/s]\u001b[A\n",
            " 71% 1163264/1648877 [00:18<00:08, 56310.73it/s]\u001b[A\n",
            " 71% 1171456/1648877 [00:18<00:08, 55785.22it/s]\u001b[A\n",
            " 72% 1179648/1648877 [00:18<00:08, 56507.21it/s]\u001b[A\n",
            " 72% 1187840/1648877 [00:18<00:08, 57071.72it/s]\u001b[A\n",
            " 73% 1196032/1648877 [00:19<00:07, 56912.17it/s]\u001b[A\n",
            " 73% 1204224/1648877 [00:19<00:07, 56814.70it/s]\u001b[A\n",
            " 74% 1212416/1648877 [00:19<00:07, 56776.75it/s]\u001b[A\n",
            " 74% 1220608/1648877 [00:19<00:07, 55951.49it/s]\u001b[A\n",
            " 75% 1228800/1648877 [00:19<00:07, 57109.21it/s]\u001b[A\n",
            " 75% 1236992/1648877 [00:19<00:07, 57015.87it/s]\u001b[A\n",
            " 76% 1245184/1648877 [00:19<00:07, 56941.76it/s]\u001b[A\n",
            " 76% 1253376/1648877 [00:20<00:06, 56881.13it/s]\u001b[A\n",
            " 77% 1261568/1648877 [00:20<00:06, 56847.65it/s]\u001b[A\n",
            " 77% 1269760/1648877 [00:20<00:06, 56709.56it/s]\u001b[A\n",
            " 78% 1277952/1648877 [00:20<00:06, 56757.30it/s]\u001b[A\n",
            " 78% 1286144/1648877 [00:20<00:06, 56364.69it/s]\u001b[A\n",
            " 78% 1294336/1648877 [00:20<00:06, 56516.57it/s]\u001b[A\n",
            " 79% 1302528/1648877 [00:20<00:06, 56898.38it/s]\u001b[A\n",
            " 79% 1310720/1648877 [00:21<00:06, 56280.45it/s]\u001b[A\n",
            " 80% 1318912/1648877 [00:21<00:05, 56389.52it/s]\u001b[A\n",
            " 80% 1327104/1648877 [00:21<00:05, 57163.98it/s]\u001b[A\n",
            " 81% 1335296/1648877 [00:21<00:05, 56930.59it/s]\u001b[A\n",
            " 81% 1343488/1648877 [00:21<00:05, 57007.45it/s]\u001b[A\n",
            " 82% 1351680/1648877 [00:21<00:05, 56268.09it/s]\u001b[A\n",
            " 82% 1359872/1648877 [00:21<00:05, 56627.59it/s]\u001b[A\n",
            " 83% 1368064/1648877 [00:22<00:04, 57081.09it/s]\u001b[A\n",
            " 83% 1376256/1648877 [00:22<00:04, 56960.98it/s]\u001b[A\n",
            " 84% 1384448/1648877 [00:22<00:04, 56882.57it/s]\u001b[A\n",
            " 84% 1392640/1648877 [00:22<00:04, 56841.58it/s]\u001b[A\n",
            " 85% 1400832/1648877 [00:22<00:04, 56833.33it/s]\u001b[A\n",
            " 85% 1409024/1648877 [00:22<00:04, 56809.20it/s]\u001b[A\n",
            " 86% 1417216/1648877 [00:22<00:04, 56679.15it/s]\u001b[A\n",
            " 86% 1425408/1648877 [00:23<00:03, 56807.36it/s]\u001b[A\n",
            " 87% 1433600/1648877 [00:23<00:03, 56276.62it/s]\u001b[A\n",
            " 87% 1441792/1648877 [00:23<00:03, 56378.89it/s]\u001b[A\n",
            " 88% 1449984/1648877 [00:23<00:03, 57065.86it/s]\u001b[A\n",
            " 88% 1458176/1648877 [00:23<00:03, 56956.23it/s]\u001b[A\n",
            " 89% 1466368/1648877 [00:23<00:03, 56833.02it/s]\u001b[A\n",
            " 89% 1474560/1648877 [00:23<00:03, 56828.35it/s]\u001b[A\n",
            " 90% 1482752/1648877 [00:24<00:02, 56842.55it/s]\u001b[A\n",
            " 90% 1490944/1648877 [00:24<00:02, 56796.52it/s]\u001b[A\n",
            " 91% 1499136/1648877 [00:24<00:02, 56792.83it/s]\u001b[A\n",
            " 91% 1507328/1648877 [00:24<00:02, 56757.83it/s]\u001b[A\n",
            " 92% 1515520/1648877 [00:24<00:02, 56730.60it/s]\u001b[A\n",
            " 92% 1523712/1648877 [00:24<00:02, 56521.55it/s]\u001b[A\n",
            " 93% 1531904/1648877 [00:24<00:02, 56828.14it/s]\u001b[A\n",
            " 93% 1540096/1648877 [00:25<00:01, 56754.40it/s]\u001b[A\n",
            " 94% 1548288/1648877 [00:25<00:01, 56724.15it/s]\u001b[A\n",
            " 94% 1556480/1648877 [00:25<00:01, 56522.68it/s]\u001b[A\n",
            " 95% 1564672/1648877 [00:25<00:01, 56795.06it/s]\u001b[A\n",
            " 95% 1572864/1648877 [00:25<00:01, 56840.09it/s]\u001b[A\n",
            " 96% 1581056/1648877 [00:25<00:01, 56816.89it/s]\u001b[A\n",
            " 96% 1589248/1648877 [00:25<00:01, 56734.91it/s]\u001b[A\n",
            " 97% 1597440/1648877 [00:26<00:00, 56766.12it/s]\u001b[A\n",
            " 97% 1605632/1648877 [00:26<00:00, 56725.24it/s]\u001b[A\n",
            " 98% 1613824/1648877 [00:26<00:00, 56568.30it/s]\u001b[A\n",
            " 98% 1622016/1648877 [00:26<00:00, 56765.42it/s]\u001b[A\n",
            " 99% 1630208/1648877 [00:26<00:00, 56720.62it/s]\u001b[A\n",
            " 99% 1638400/1648877 [00:26<00:00, 56375.94it/s]\u001b[A\n",
            "100% 1646592/1648877 [00:26<00:00, 56860.25it/s]\u001b[A\n",
            "1654784it [00:27, 52522.48it/s]                 \u001b[AExtracting /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-images-idx3-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "  0% 0/4542 [00:00<?, ?it/s]\u001b[A\u001b[AExtracting /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw/t10k-labels-idx1-ubyte.gz to /fsdl-text-recognizer-2021-labs/data/downloaded/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "2021-07-18 22:31:20.950989: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 936 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 803 K \n",
            "3 | model.fc2     | Linear   | 131 K \n",
            "4 | model.fc3     | Linear   | 1.3 K \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "936 K     Trainable params\n",
            "0         Non-trainable params\n",
            "936 K     Total params\n",
            "Validation sanity check: 0it [00:00, ?it/s]\n",
            "\n",
            "\u001b[A\u001b[A\n",
            "Epoch 0:  91% 430/470 [00:17<00:01, 24.19it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  92% 433/470 [00:17<00:01, 24.29it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  93% 438/470 [00:17<00:01, 24.38it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  20% 8/40 [00:00<00:00, 37.12it/s]\u001b[A\n",
            "Epoch 0:  94% 443/470 [00:18<00:01, 24.47it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  95% 448/470 [00:18<00:00, 24.58it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  96% 453/470 [00:18<00:00, 24.67it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0:  97% 458/470 [00:18<00:00, 24.76it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Validating:  70% 28/40 [00:00<00:00, 38.05it/s]\u001b[A\n",
            "Epoch 0:  99% 463/470 [00:18<00:00, 24.86it/s, loss=0.212, v_num=0, val_loss=2.33, val_acc=0.0664]\n",
            "Epoch 0: 100% 470/470 [00:18<00:00, 24.94it/s, loss=0.212, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  91% 430/470 [00:17<00:01, 24.82it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating: 0it [00:00, ?it/s]\u001b[A\n",
            "Epoch 1:  93% 435/470 [00:17<00:01, 24.95it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  94% 440/470 [00:17<00:01, 25.05it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  95% 445/470 [00:17<00:00, 25.14it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  96% 450/470 [00:17<00:00, 25.22it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Validating:  50% 20/40 [00:00<00:00, 36.71it/s]\u001b[A\n",
            "Epoch 1:  97% 455/470 [00:17<00:00, 25.31it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  98% 460/470 [00:18<00:00, 25.40it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1:  99% 465/470 [00:18<00:00, 25.48it/s, loss=0.158, v_num=0, val_loss=0.162, val_acc=0.953]\n",
            "Epoch 1: 100% 470/470 [00:18<00:00, 25.51it/s, loss=0.158, v_num=0, val_loss=0.12, val_acc=0.966] \n",
            "Epoch 2:  91% 430/470 [00:18<00:01, 23.05it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  93% 435/470 [00:18<00:01, 23.19it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  12% 5/40 [00:00<00:00, 39.68it/s]\u001b[A\n",
            "Epoch 2:  94% 440/470 [00:18<00:01, 23.29it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  95% 445/470 [00:19<00:01, 23.40it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  96% 450/470 [00:19<00:00, 23.51it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  97% 455/470 [00:19<00:00, 23.61it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  98% 460/470 [00:19<00:00, 23.71it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2:  99% 465/470 [00:19<00:00, 23.82it/s, loss=0.124, v_num=0, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 2: 100% 470/470 [00:19<00:00, 23.88it/s, loss=0.124, v_num=0, val_loss=0.108, val_acc=0.969]\n",
            "                                               \u001b[A\n",
            "Epoch 2: 100% 470/470 [00:19<00:00, 23.85it/s, loss=0.124, v_num=0, val_loss=0.108, val_acc=0.969]\n",
            "Testing: 100% 79/79 [00:01<00:00, 39.59it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9730)}\n",
            "--------------------------------------------------------------------------------\n",
            "8192it [01:01, 133.65it/s]\n",
            "1654784it [01:28, 18694.33it/s]\n",
            "9920512it [05:01, 32929.69it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxjM3aFuvF7F",
        "outputId": "7ec109bb-3229-439e-e403-8e6edd0097c7"
      },
      "source": [
        "ls"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "readme.md  \u001b[0m\u001b[01;34mtext_recognizer\u001b[0m/  \u001b[01;34mtraining\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "e8HJoiFlvtuV",
        "outputId": "eaf65184-3cc2-4d60-b027-a9e607693a9c"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/fsdl-text-recognizer-2021-labs/lab1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "hIsUFiGCvwFt",
        "outputId": "ae5211fb-6b0a-4e2f-d0ff-adf608e6948e"
      },
      "source": [
        "git pull"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-43-9c5a8574ec5a>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    git pull\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5Rsff4mvyEG",
        "outputId": "8775ff25-7e0d-4d59-c686-1def7e64f9ce"
      },
      "source": [
        "!git pull"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already up to date.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AlcgwqFs5qt",
        "outputId": "851f89a4-7e04-4f7b-b7a3-b06d5aca3382"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --max_epoch=5, --fc1=128 --fc2=64"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "usage: run_experiment.py [--logger [LOGGER]]\n",
            "                         [--checkpoint_callback [CHECKPOINT_CALLBACK]]\n",
            "                         [--default_root_dir DEFAULT_ROOT_DIR]\n",
            "                         [--gradient_clip_val GRADIENT_CLIP_VAL]\n",
            "                         [--process_position PROCESS_POSITION]\n",
            "                         [--num_nodes NUM_NODES]\n",
            "                         [--num_processes NUM_PROCESSES] [--gpus GPUS]\n",
            "                         [--auto_select_gpus [AUTO_SELECT_GPUS]]\n",
            "                         [--tpu_cores TPU_CORES]\n",
            "                         [--log_gpu_memory LOG_GPU_MEMORY]\n",
            "                         [--progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE]\n",
            "                         [--overfit_batches OVERFIT_BATCHES]\n",
            "                         [--track_grad_norm TRACK_GRAD_NORM]\n",
            "                         [--check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
            "                         [--fast_dev_run [FAST_DEV_RUN]]\n",
            "                         [--accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
            "                         [--max_epochs MAX_EPOCHS] [--min_epochs MIN_EPOCHS]\n",
            "                         [--max_steps MAX_STEPS] [--min_steps MIN_STEPS]\n",
            "                         [--limit_train_batches LIMIT_TRAIN_BATCHES]\n",
            "                         [--limit_val_batches LIMIT_VAL_BATCHES]\n",
            "                         [--limit_test_batches LIMIT_TEST_BATCHES]\n",
            "                         [--val_check_interval VAL_CHECK_INTERVAL]\n",
            "                         [--flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS]\n",
            "                         [--log_every_n_steps LOG_EVERY_N_STEPS]\n",
            "                         [--accelerator ACCELERATOR]\n",
            "                         [--sync_batchnorm [SYNC_BATCHNORM]]\n",
            "                         [--precision PRECISION]\n",
            "                         [--weights_summary WEIGHTS_SUMMARY]\n",
            "                         [--weights_save_path WEIGHTS_SAVE_PATH]\n",
            "                         [--num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
            "                         [--truncated_bptt_steps TRUNCATED_BPTT_STEPS]\n",
            "                         [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                         [--profiler [PROFILER]] [--benchmark [BENCHMARK]]\n",
            "                         [--deterministic [DETERMINISTIC]]\n",
            "                         [--reload_dataloaders_every_epoch [RELOAD_DATALOADERS_EVERY_EPOCH]]\n",
            "                         [--auto_lr_find [AUTO_LR_FIND]]\n",
            "                         [--replace_sampler_ddp [REPLACE_SAMPLER_DDP]]\n",
            "                         [--terminate_on_nan [TERMINATE_ON_NAN]]\n",
            "                         [--auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]]\n",
            "                         [--prepare_data_per_node [PREPARE_DATA_PER_NODE]]\n",
            "                         [--plugins PLUGINS] [--amp_backend AMP_BACKEND]\n",
            "                         [--amp_level AMP_LEVEL]\n",
            "                         [--distributed_backend DISTRIBUTED_BACKEND]\n",
            "                         [--automatic_optimization [AUTOMATIC_OPTIMIZATION]]\n",
            "                         [--move_metrics_to_cpu [MOVE_METRICS_TO_CPU]]\n",
            "                         [--enable_pl_optimizer [ENABLE_PL_OPTIMIZER]]\n",
            "                         [--data_class DATA_CLASS] [--model_class MODEL_CLASS]\n",
            "                         [--load_checkpoint LOAD_CHECKPOINT]\n",
            "run_experiment.py: error: argument --max_epochs: invalid int value: '5,'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzLncZPexRyh",
        "outputId": "27f4af16-9d62-4f0a-b362-ba8416054be7"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --max_epochs=5, --fc1=128 --fc2=64"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "usage: run_experiment.py [--logger [LOGGER]]\n",
            "                         [--checkpoint_callback [CHECKPOINT_CALLBACK]]\n",
            "                         [--default_root_dir DEFAULT_ROOT_DIR]\n",
            "                         [--gradient_clip_val GRADIENT_CLIP_VAL]\n",
            "                         [--process_position PROCESS_POSITION]\n",
            "                         [--num_nodes NUM_NODES]\n",
            "                         [--num_processes NUM_PROCESSES] [--gpus GPUS]\n",
            "                         [--auto_select_gpus [AUTO_SELECT_GPUS]]\n",
            "                         [--tpu_cores TPU_CORES]\n",
            "                         [--log_gpu_memory LOG_GPU_MEMORY]\n",
            "                         [--progress_bar_refresh_rate PROGRESS_BAR_REFRESH_RATE]\n",
            "                         [--overfit_batches OVERFIT_BATCHES]\n",
            "                         [--track_grad_norm TRACK_GRAD_NORM]\n",
            "                         [--check_val_every_n_epoch CHECK_VAL_EVERY_N_EPOCH]\n",
            "                         [--fast_dev_run [FAST_DEV_RUN]]\n",
            "                         [--accumulate_grad_batches ACCUMULATE_GRAD_BATCHES]\n",
            "                         [--max_epochs MAX_EPOCHS] [--min_epochs MIN_EPOCHS]\n",
            "                         [--max_steps MAX_STEPS] [--min_steps MIN_STEPS]\n",
            "                         [--limit_train_batches LIMIT_TRAIN_BATCHES]\n",
            "                         [--limit_val_batches LIMIT_VAL_BATCHES]\n",
            "                         [--limit_test_batches LIMIT_TEST_BATCHES]\n",
            "                         [--val_check_interval VAL_CHECK_INTERVAL]\n",
            "                         [--flush_logs_every_n_steps FLUSH_LOGS_EVERY_N_STEPS]\n",
            "                         [--log_every_n_steps LOG_EVERY_N_STEPS]\n",
            "                         [--accelerator ACCELERATOR]\n",
            "                         [--sync_batchnorm [SYNC_BATCHNORM]]\n",
            "                         [--precision PRECISION]\n",
            "                         [--weights_summary WEIGHTS_SUMMARY]\n",
            "                         [--weights_save_path WEIGHTS_SAVE_PATH]\n",
            "                         [--num_sanity_val_steps NUM_SANITY_VAL_STEPS]\n",
            "                         [--truncated_bptt_steps TRUNCATED_BPTT_STEPS]\n",
            "                         [--resume_from_checkpoint RESUME_FROM_CHECKPOINT]\n",
            "                         [--profiler [PROFILER]] [--benchmark [BENCHMARK]]\n",
            "                         [--deterministic [DETERMINISTIC]]\n",
            "                         [--reload_dataloaders_every_epoch [RELOAD_DATALOADERS_EVERY_EPOCH]]\n",
            "                         [--auto_lr_find [AUTO_LR_FIND]]\n",
            "                         [--replace_sampler_ddp [REPLACE_SAMPLER_DDP]]\n",
            "                         [--terminate_on_nan [TERMINATE_ON_NAN]]\n",
            "                         [--auto_scale_batch_size [AUTO_SCALE_BATCH_SIZE]]\n",
            "                         [--prepare_data_per_node [PREPARE_DATA_PER_NODE]]\n",
            "                         [--plugins PLUGINS] [--amp_backend AMP_BACKEND]\n",
            "                         [--amp_level AMP_LEVEL]\n",
            "                         [--distributed_backend DISTRIBUTED_BACKEND]\n",
            "                         [--automatic_optimization [AUTOMATIC_OPTIMIZATION]]\n",
            "                         [--move_metrics_to_cpu [MOVE_METRICS_TO_CPU]]\n",
            "                         [--enable_pl_optimizer [ENABLE_PL_OPTIMIZER]]\n",
            "                         [--data_class DATA_CLASS] [--model_class MODEL_CLASS]\n",
            "                         [--load_checkpoint LOAD_CHECKPOINT]\n",
            "run_experiment.py: error: argument --max_epochs: invalid int value: '5,'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJEuCADQxcYz",
        "outputId": "82911895-3f5a-413e-f9cc-9b8b253f0e68"
      },
      "source": [
        "!python3 training/run_experiment.py --model_class=MLP --data_class=MNIST --fc1=128 --fc2=64"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.6) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: You have set progress_bar_refresh_rate < 20 on Google Colab. This may crash. Consider using progress_bar_refresh_rate >= 20 in Trainer.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "GPU available: True, used: False\n",
            "TPU available: None, using: 0 TPU cores\n",
            "/usr/local/lib/python3.7/dist-packages/pytorch_lightning/utilities/distributed.py:49: UserWarning: GPU available but not used. Set the --gpus flag when calling the script.\n",
            "  warnings.warn(*args, **kwargs)\n",
            "2021-07-18 22:39:59.248062: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
            "\n",
            "  | Name          | Type     | Params\n",
            "-------------------------------------------\n",
            "0 | model         | MLP      | 109 K \n",
            "1 | model.dropout | Dropout  | 0     \n",
            "2 | model.fc1     | Linear   | 100 K \n",
            "3 | model.fc2     | Linear   | 8.3 K \n",
            "4 | model.fc3     | Linear   | 650   \n",
            "5 | train_acc     | Accuracy | 0     \n",
            "6 | val_acc       | Accuracy | 0     \n",
            "7 | test_acc      | Accuracy | 0     \n",
            "-------------------------------------------\n",
            "109 K     Trainable params\n",
            "0         Non-trainable params\n",
            "109 K     Total params\n",
            "Epoch 0:  91% 430/470 [00:10<00:01, 39.43it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  93% 435/470 [00:11<00:00, 39.54it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.96it/s]\u001b[A\n",
            "Epoch 0:  94% 441/470 [00:11<00:00, 39.59it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  95% 447/470 [00:11<00:00, 39.59it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  96% 453/470 [00:11<00:00, 39.62it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0:  98% 459/470 [00:11<00:00, 39.66it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Validating:  72% 29/40 [00:00<00:00, 42.07it/s]\u001b[A\n",
            "Epoch 0:  99% 465/470 [00:11<00:00, 39.69it/s, loss=0.402, v_num=1, val_loss=2.31, val_acc=0.145]\n",
            "Epoch 0: 100% 470/470 [00:11<00:00, 39.65it/s, loss=0.402, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  91% 430/470 [00:11<00:01, 36.16it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  92% 432/470 [00:11<00:01, 36.26it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  93% 438/470 [00:12<00:00, 36.32it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  94% 444/470 [00:12<00:00, 36.36it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  96% 450/470 [00:12<00:00, 36.44it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Validating:  50% 20/40 [00:00<00:00, 42.42it/s]\u001b[A\n",
            "Epoch 1:  97% 456/470 [00:12<00:00, 36.52it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1:  98% 462/470 [00:12<00:00, 36.59it/s, loss=0.312, v_num=1, val_loss=0.237, val_acc=0.933]\n",
            "Epoch 1: 100% 470/470 [00:12<00:00, 36.67it/s, loss=0.312, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  91% 430/470 [00:11<00:01, 37.10it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  92% 433/470 [00:11<00:00, 37.23it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  94% 440/470 [00:11<00:00, 37.33it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Validating:  25% 10/40 [00:00<00:00, 45.02it/s]\u001b[A\n",
            "Epoch 2:  95% 447/470 [00:11<00:00, 37.45it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2:  97% 454/470 [00:12<00:00, 37.53it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.16it/s]\u001b[A\n",
            "Epoch 2:  98% 461/470 [00:12<00:00, 37.65it/s, loss=0.271, v_num=1, val_loss=0.173, val_acc=0.949]\n",
            "Epoch 2: 100% 470/470 [00:12<00:00, 37.76it/s, loss=0.271, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  91% 430/470 [00:10<00:01, 39.15it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  92% 434/470 [00:11<00:00, 39.29it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Validating:  12% 5/40 [00:00<00:00, 47.71it/s]\u001b[A\n",
            "Epoch 3:  94% 441/470 [00:11<00:00, 39.36it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  95% 448/470 [00:11<00:00, 39.45it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3:  97% 455/470 [00:11<00:00, 39.55it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.68it/s]\u001b[A\n",
            "Epoch 3:  98% 462/470 [00:11<00:00, 39.62it/s, loss=0.287, v_num=1, val_loss=0.162, val_acc=0.951]\n",
            "Epoch 3: 100% 470/470 [00:11<00:00, 39.65it/s, loss=0.287, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  91% 430/470 [00:10<00:01, 39.73it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  92% 434/470 [00:10<00:00, 39.86it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Validating:  12% 5/40 [00:00<00:00, 47.22it/s]\u001b[A\n",
            "Epoch 4:  94% 441/470 [00:11<00:00, 39.97it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  95% 448/470 [00:11<00:00, 40.08it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4:  97% 455/470 [00:11<00:00, 40.13it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Validating:  65% 26/40 [00:00<00:00, 46.40it/s]\u001b[A\n",
            "Epoch 4:  98% 462/470 [00:11<00:00, 40.20it/s, loss=0.246, v_num=1, val_loss=0.138, val_acc=0.961]\n",
            "Epoch 4: 100% 470/470 [00:11<00:00, 40.28it/s, loss=0.246, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  91% 430/470 [00:10<00:01, 39.29it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966] \n",
            "Epoch 5:  92% 434/470 [00:11<00:00, 39.43it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Validating:  12% 5/40 [00:00<00:00, 46.20it/s]\u001b[A\n",
            "Epoch 5:  94% 441/470 [00:11<00:00, 39.53it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  95% 448/470 [00:11<00:00, 39.61it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5:  97% 455/470 [00:11<00:00, 39.70it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.51it/s]\u001b[A\n",
            "Epoch 5:  98% 462/470 [00:11<00:00, 39.77it/s, loss=0.22, v_num=1, val_loss=0.128, val_acc=0.966]\n",
            "Epoch 5: 100% 470/470 [00:11<00:00, 39.78it/s, loss=0.22, v_num=1, val_loss=0.12, val_acc=0.966] \n",
            "Epoch 6:  91% 430/470 [00:11<00:01, 36.56it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  92% 434/470 [00:11<00:00, 36.68it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.54it/s]\u001b[A\n",
            "Epoch 6:  94% 441/470 [00:11<00:00, 36.76it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  95% 448/470 [00:12<00:00, 36.84it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6:  97% 455/470 [00:12<00:00, 36.89it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Validating:  62% 25/40 [00:00<00:00, 41.81it/s]\u001b[A\n",
            "Epoch 6:  98% 462/470 [00:12<00:00, 36.96it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6: 100% 469/470 [00:12<00:00, 37.02it/s, loss=0.232, v_num=1, val_loss=0.12, val_acc=0.966]\n",
            "Epoch 6: 100% 470/470 [00:12<00:00, 36.99it/s, loss=0.232, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  91% 430/470 [00:11<00:01, 36.27it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  92% 434/470 [00:11<00:00, 36.40it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.02it/s]\u001b[A\n",
            "Epoch 7:  94% 441/470 [00:12<00:00, 36.47it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  95% 448/470 [00:12<00:00, 36.57it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7:  97% 455/470 [00:12<00:00, 36.65it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Validating:  62% 25/40 [00:00<00:00, 42.87it/s]\u001b[A\n",
            "Epoch 7:  98% 462/470 [00:12<00:00, 36.74it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7: 100% 469/470 [00:12<00:00, 36.81it/s, loss=0.216, v_num=1, val_loss=0.119, val_acc=0.969]\n",
            "Epoch 7: 100% 470/470 [00:12<00:00, 36.78it/s, loss=0.216, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  91% 430/470 [00:11<00:01, 38.77it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  92% 434/470 [00:11<00:00, 38.85it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Validating:  10% 4/40 [00:00<00:00, 38.92it/s]\u001b[A\n",
            "Epoch 8:  94% 441/470 [00:11<00:00, 38.87it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  95% 448/470 [00:11<00:00, 38.91it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Validating:  48% 19/40 [00:00<00:00, 40.51it/s]\u001b[A\n",
            "Epoch 8:  97% 455/470 [00:11<00:00, 38.96it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8:  98% 462/470 [00:11<00:00, 39.01it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8: 100% 469/470 [00:12<00:00, 39.04it/s, loss=0.233, v_num=1, val_loss=0.114, val_acc=0.967]\n",
            "Epoch 8: 100% 470/470 [00:12<00:00, 39.01it/s, loss=0.233, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9:  91% 430/470 [00:12<00:01, 35.77it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969] \n",
            "Epoch 9:  92% 434/470 [00:12<00:01, 35.89it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.20it/s]\u001b[A\n",
            "Epoch 9:  94% 441/470 [00:12<00:00, 35.96it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9:  95% 448/470 [00:12<00:00, 36.04it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  48% 19/40 [00:00<00:00, 42.02it/s]\u001b[A\n",
            "Epoch 9:  97% 455/470 [00:12<00:00, 36.14it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Epoch 9:  98% 462/470 [00:12<00:00, 36.19it/s, loss=0.22, v_num=1, val_loss=0.109, val_acc=0.969]\n",
            "Validating:  82% 33/40 [00:00<00:00, 41.37it/s]\u001b[A\n",
            "Epoch 9: 100% 470/470 [00:12<00:00, 36.24it/s, loss=0.22, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  91% 430/470 [00:11<00:01, 36.52it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  92% 434/470 [00:11<00:00, 36.66it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 46.84it/s]\u001b[A\n",
            "Epoch 10:  94% 441/470 [00:11<00:00, 36.80it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  95% 448/470 [00:12<00:00, 36.93it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10:  97% 455/470 [00:12<00:00, 37.06it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 47.15it/s]\u001b[A\n",
            "Epoch 10:  98% 462/470 [00:12<00:00, 37.15it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 10: 100% 470/470 [00:12<00:00, 37.26it/s, loss=0.183, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  91% 430/470 [00:11<00:01, 39.05it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  92% 434/470 [00:11<00:00, 39.17it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.85it/s]\u001b[A\n",
            "Epoch 11:  94% 441/470 [00:11<00:00, 39.28it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  95% 448/470 [00:11<00:00, 39.38it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11:  97% 455/470 [00:11<00:00, 39.47it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.15it/s]\u001b[A\n",
            "Epoch 11:  98% 462/470 [00:11<00:00, 39.57it/s, loss=0.177, v_num=1, val_loss=0.107, val_acc=0.971]\n",
            "Epoch 11: 100% 470/470 [00:11<00:00, 39.65it/s, loss=0.177, v_num=1, val_loss=0.1, val_acc=0.97]   \n",
            "Epoch 12:  91% 430/470 [00:10<00:01, 39.13it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  92% 434/470 [00:11<00:00, 39.26it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Validating:  12% 5/40 [00:00<00:00, 47.02it/s]\u001b[A\n",
            "Epoch 12:  94% 441/470 [00:11<00:00, 39.37it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  95% 448/470 [00:11<00:00, 39.42it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12:  97% 455/470 [00:11<00:00, 39.52it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.23it/s]\u001b[A\n",
            "Epoch 12:  98% 462/470 [00:11<00:00, 39.59it/s, loss=0.214, v_num=1, val_loss=0.1, val_acc=0.97]\n",
            "Epoch 12: 100% 470/470 [00:11<00:00, 39.66it/s, loss=0.214, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  91% 430/470 [00:10<00:01, 39.42it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  92% 434/470 [00:10<00:00, 39.56it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.15it/s]\u001b[A\n",
            "Epoch 13:  94% 441/470 [00:11<00:00, 39.65it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  95% 448/470 [00:11<00:00, 39.76it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13:  97% 455/470 [00:11<00:00, 39.83it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.27it/s]\u001b[A\n",
            "Epoch 13:  98% 462/470 [00:11<00:00, 39.91it/s, loss=0.189, v_num=1, val_loss=0.099, val_acc=0.973]\n",
            "Epoch 13: 100% 470/470 [00:11<00:00, 39.98it/s, loss=0.189, v_num=1, val_loss=0.1, val_acc=0.973]  \n",
            "Epoch 14:  91% 430/470 [00:11<00:01, 36.47it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  92% 434/470 [00:11<00:00, 36.59it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.33it/s]\u001b[A\n",
            "Epoch 14:  94% 441/470 [00:12<00:00, 36.63it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  95% 448/470 [00:12<00:00, 36.71it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Validating:  48% 19/40 [00:00<00:00, 41.63it/s]\u001b[A\n",
            "Epoch 14:  97% 455/470 [00:12<00:00, 36.80it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14:  98% 462/470 [00:12<00:00, 36.86it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14: 100% 469/470 [00:12<00:00, 36.93it/s, loss=0.174, v_num=1, val_loss=0.1, val_acc=0.973]\n",
            "Epoch 14: 100% 470/470 [00:12<00:00, 36.93it/s, loss=0.174, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  91% 430/470 [00:12<00:01, 35.80it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971] \n",
            "Epoch 15:  92% 434/470 [00:12<00:01, 35.91it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.68it/s]\u001b[A\n",
            "Epoch 15:  94% 441/470 [00:12<00:00, 35.99it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  95% 448/470 [00:12<00:00, 36.06it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Validating:  48% 19/40 [00:00<00:00, 41.15it/s]\u001b[A\n",
            "Epoch 15:  97% 455/470 [00:12<00:00, 36.16it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15:  98% 462/470 [00:12<00:00, 36.24it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15: 100% 469/470 [00:12<00:00, 36.33it/s, loss=0.18, v_num=1, val_loss=0.0992, val_acc=0.971]\n",
            "Epoch 15: 100% 470/470 [00:12<00:00, 36.31it/s, loss=0.18, v_num=1, val_loss=0.103, val_acc=0.971] \n",
            "Epoch 16:  91% 430/470 [00:11<00:01, 38.62it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  92% 434/470 [00:11<00:00, 38.72it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.06it/s]\u001b[A\n",
            "Epoch 16:  94% 441/470 [00:11<00:00, 38.80it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  95% 448/470 [00:11<00:00, 38.90it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16:  97% 455/470 [00:11<00:00, 38.98it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.31it/s]\u001b[A\n",
            "Epoch 16:  98% 462/470 [00:11<00:00, 39.08it/s, loss=0.184, v_num=1, val_loss=0.103, val_acc=0.971]\n",
            "Epoch 16: 100% 470/470 [00:12<00:00, 39.15it/s, loss=0.184, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  91% 430/470 [00:11<00:01, 38.67it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  92% 434/470 [00:11<00:00, 38.80it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 45.11it/s]\u001b[A\n",
            "Epoch 17:  94% 441/470 [00:11<00:00, 38.86it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  95% 448/470 [00:11<00:00, 38.98it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17:  97% 455/470 [00:11<00:00, 39.07it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.50it/s]\u001b[A\n",
            "Epoch 17:  98% 462/470 [00:11<00:00, 39.13it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17: 100% 469/470 [00:11<00:00, 39.16it/s, loss=0.192, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 17: 100% 470/470 [00:12<00:00, 39.15it/s, loss=0.192, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  91% 430/470 [00:10<00:01, 39.35it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  92% 434/470 [00:10<00:00, 39.48it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 44.17it/s]\u001b[A\n",
            "Epoch 18:  94% 441/470 [00:11<00:00, 39.56it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  95% 448/470 [00:11<00:00, 39.64it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18:  97% 455/470 [00:11<00:00, 39.71it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.05it/s]\u001b[A\n",
            "Epoch 18:  98% 462/470 [00:11<00:00, 39.75it/s, loss=0.154, v_num=1, val_loss=0.0958, val_acc=0.974]\n",
            "Epoch 18: 100% 470/470 [00:11<00:00, 39.83it/s, loss=0.154, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  91% 430/470 [00:11<00:01, 38.18it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974] \n",
            "Epoch 19:  92% 434/470 [00:11<00:00, 38.31it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 44.61it/s]\u001b[A\n",
            "Epoch 19:  94% 441/470 [00:11<00:00, 38.34it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  95% 448/470 [00:11<00:00, 38.39it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Validating:  48% 19/40 [00:00<00:00, 43.02it/s]\u001b[A\n",
            "Epoch 19:  97% 455/470 [00:11<00:00, 38.46it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19:  98% 462/470 [00:11<00:00, 38.51it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19: 100% 469/470 [00:12<00:00, 38.58it/s, loss=0.16, v_num=1, val_loss=0.0966, val_acc=0.974]\n",
            "Epoch 19: 100% 470/470 [00:12<00:00, 38.57it/s, loss=0.16, v_num=1, val_loss=0.101, val_acc=0.972] \n",
            "Epoch 20:  91% 430/470 [00:11<00:01, 36.20it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  92% 434/470 [00:11<00:00, 36.34it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.89it/s]\u001b[A\n",
            "Epoch 20:  94% 441/470 [00:12<00:00, 36.43it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  95% 448/470 [00:12<00:00, 36.47it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  48% 19/40 [00:00<00:00, 42.04it/s]\u001b[A\n",
            "Epoch 20:  97% 455/470 [00:12<00:00, 36.56it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Epoch 20:  98% 462/470 [00:12<00:00, 36.58it/s, loss=0.149, v_num=1, val_loss=0.101, val_acc=0.972]\n",
            "Validating:  82% 33/40 [00:00<00:00, 41.07it/s]\u001b[A\n",
            "Epoch 20: 100% 470/470 [00:12<00:00, 36.66it/s, loss=0.149, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  91% 430/470 [00:11<00:01, 37.66it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  92% 434/470 [00:11<00:00, 37.78it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Validating:  12% 5/40 [00:00<00:00, 41.83it/s]\u001b[A\n",
            "Epoch 21:  94% 441/470 [00:11<00:00, 37.84it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  95% 448/470 [00:11<00:00, 37.95it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21:  97% 455/470 [00:11<00:00, 38.04it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.96it/s]\u001b[A\n",
            "Epoch 21:  98% 462/470 [00:12<00:00, 38.12it/s, loss=0.143, v_num=1, val_loss=0.0979, val_acc=0.972]\n",
            "Epoch 21: 100% 470/470 [00:12<00:00, 38.22it/s, loss=0.143, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  91% 430/470 [00:11<00:01, 38.78it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975] \n",
            "Epoch 22:  92% 434/470 [00:11<00:00, 38.92it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Validating:  12% 5/40 [00:00<00:00, 47.59it/s]\u001b[A\n",
            "Epoch 22:  94% 441/470 [00:11<00:00, 39.02it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  95% 448/470 [00:11<00:00, 39.10it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22:  97% 455/470 [00:11<00:00, 39.20it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Validating:  62% 25/40 [00:00<00:00, 46.58it/s]\u001b[A\n",
            "Epoch 22:  98% 462/470 [00:11<00:00, 39.29it/s, loss=0.18, v_num=1, val_loss=0.0907, val_acc=0.975]\n",
            "Epoch 22: 100% 470/470 [00:11<00:00, 39.38it/s, loss=0.18, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  91% 430/470 [00:10<00:01, 39.33it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  92% 434/470 [00:11<00:00, 39.40it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Validating:  10% 4/40 [00:00<00:00, 38.95it/s]\u001b[A\n",
            "Epoch 23:  94% 441/470 [00:11<00:00, 39.48it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  95% 448/470 [00:11<00:00, 39.55it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Validating:  48% 19/40 [00:00<00:00, 43.07it/s]\u001b[A\n",
            "Epoch 23:  97% 455/470 [00:11<00:00, 39.65it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23:  98% 462/470 [00:11<00:00, 39.75it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23: 100% 469/470 [00:11<00:00, 39.81it/s, loss=0.156, v_num=1, val_loss=0.0977, val_acc=0.974]\n",
            "Epoch 23: 100% 470/470 [00:11<00:00, 39.82it/s, loss=0.156, v_num=1, val_loss=0.097, val_acc=0.973] \n",
            "Epoch 24:  91% 430/470 [00:10<00:01, 39.63it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  92% 434/470 [00:10<00:00, 39.73it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.75it/s]\u001b[A\n",
            "Epoch 24:  94% 441/470 [00:11<00:00, 39.83it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  95% 448/470 [00:11<00:00, 39.88it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Validating:  50% 20/40 [00:00<00:00, 43.82it/s]\u001b[A\n",
            "Epoch 24:  97% 455/470 [00:11<00:00, 39.89it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24:  98% 462/470 [00:11<00:00, 39.93it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24: 100% 469/470 [00:11<00:00, 39.96it/s, loss=0.146, v_num=1, val_loss=0.097, val_acc=0.973]\n",
            "Epoch 24: 100% 470/470 [00:11<00:00, 39.95it/s, loss=0.146, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  91% 430/470 [00:12<00:01, 35.54it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  92% 434/470 [00:12<00:01, 35.67it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  12% 5/40 [00:00<00:00, 40.19it/s]\u001b[A\n",
            "Epoch 25:  94% 441/470 [00:12<00:00, 35.72it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  95% 448/470 [00:12<00:00, 35.79it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  48% 19/40 [00:00<00:00, 40.22it/s]\u001b[A\n",
            "Epoch 25:  97% 455/470 [00:12<00:00, 35.87it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Epoch 25:  98% 462/470 [00:12<00:00, 35.93it/s, loss=0.141, v_num=1, val_loss=0.0927, val_acc=0.975]\n",
            "Validating:  85% 34/40 [00:00<00:00, 40.83it/s]\u001b[A\n",
            "Epoch 25: 100% 470/470 [00:13<00:00, 35.99it/s, loss=0.141, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  91% 430/470 [00:12<00:01, 35.82it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  92% 434/470 [00:12<00:01, 35.96it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 46.03it/s]\u001b[A\n",
            "Epoch 26:  94% 441/470 [00:12<00:00, 36.08it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  95% 448/470 [00:12<00:00, 36.20it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26:  97% 455/470 [00:12<00:00, 36.30it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 45.60it/s]\u001b[A\n",
            "Epoch 26:  98% 462/470 [00:12<00:00, 36.41it/s, loss=0.154, v_num=1, val_loss=0.0951, val_acc=0.974]\n",
            "Epoch 26: 100% 470/470 [00:12<00:00, 36.54it/s, loss=0.154, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  91% 430/470 [00:11<00:01, 38.73it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  92% 434/470 [00:11<00:00, 38.84it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.48it/s]\u001b[A\n",
            "Epoch 27:  94% 441/470 [00:11<00:00, 38.93it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  95% 448/470 [00:11<00:00, 39.02it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27:  97% 455/470 [00:11<00:00, 39.10it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Validating:  62% 25/40 [00:00<00:00, 44.74it/s]\u001b[A\n",
            "Epoch 27:  98% 462/470 [00:11<00:00, 39.17it/s, loss=0.152, v_num=1, val_loss=0.0976, val_acc=0.973]\n",
            "Epoch 27: 100% 470/470 [00:11<00:00, 39.28it/s, loss=0.152, v_num=1, val_loss=0.1, val_acc=0.974]   \n",
            "Epoch 28:  91% 430/470 [00:11<00:01, 38.85it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  92% 434/470 [00:11<00:00, 38.98it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 43.29it/s]\u001b[A\n",
            "Epoch 28:  94% 441/470 [00:11<00:00, 39.04it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  95% 448/470 [00:11<00:00, 39.14it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28:  97% 455/470 [00:11<00:00, 39.16it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Validating:  62% 25/40 [00:00<00:00, 43.51it/s]\u001b[A\n",
            "Epoch 28:  98% 462/470 [00:11<00:00, 39.25it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28: 100% 469/470 [00:11<00:00, 39.30it/s, loss=0.169, v_num=1, val_loss=0.1, val_acc=0.974]\n",
            "Epoch 28: 100% 470/470 [00:11<00:00, 39.29it/s, loss=0.169, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  91% 430/470 [00:11<00:01, 38.73it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  92% 434/470 [00:11<00:00, 38.88it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Validating:  12% 5/40 [00:00<00:00, 48.40it/s]\u001b[A\n",
            "Epoch 29:  94% 441/470 [00:11<00:00, 38.98it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  95% 448/470 [00:11<00:00, 39.07it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29:  97% 455/470 [00:11<00:00, 39.16it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Validating:  62% 25/40 [00:00<00:00, 47.01it/s]\u001b[A\n",
            "Epoch 29:  98% 462/470 [00:11<00:00, 39.22it/s, loss=0.159, v_num=1, val_loss=0.0991, val_acc=0.971]\n",
            "Epoch 29: 100% 470/470 [00:11<00:00, 39.32it/s, loss=0.159, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  91% 430/470 [00:11<00:01, 36.39it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  92% 434/470 [00:11<00:00, 36.47it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Validating:  10% 4/40 [00:00<00:00, 37.89it/s]\u001b[A\n",
            "Epoch 30:  94% 441/470 [00:12<00:00, 36.55it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  95% 448/470 [00:12<00:00, 36.58it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Validating:  48% 19/40 [00:00<00:00, 38.44it/s]\u001b[A\n",
            "Epoch 30:  97% 455/470 [00:12<00:00, 36.63it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Epoch 30:  98% 462/470 [00:12<00:00, 36.69it/s, loss=0.173, v_num=1, val_loss=0.0948, val_acc=0.973]\n",
            "Validating:  82% 33/40 [00:00<00:00, 40.25it/s]\u001b[A\n",
            "Epoch 30: 100% 470/470 [00:12<00:00, 36.74it/s, loss=0.173, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  91% 430/470 [00:12<00:01, 35.40it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  92% 434/470 [00:12<00:01, 35.52it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  12% 5/40 [00:00<00:00, 42.47it/s]\u001b[A\n",
            "Epoch 31:  94% 441/470 [00:12<00:00, 35.62it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  95% 448/470 [00:12<00:00, 35.69it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  48% 19/40 [00:00<00:00, 41.92it/s]\u001b[A\n",
            "Epoch 31:  97% 455/470 [00:12<00:00, 35.76it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Epoch 31:  98% 462/470 [00:12<00:00, 35.84it/s, loss=0.148, v_num=1, val_loss=0.0926, val_acc=0.974]\n",
            "Validating:  82% 33/40 [00:00<00:00, 41.42it/s]\u001b[A\n",
            "Epoch 31: 100% 470/470 [00:13<00:00, 35.90it/s, loss=0.148, v_num=1, val_loss=0.0959, val_acc=0.974]\n",
            "Epoch 31: 100% 470/470 [00:13<00:00, 35.82it/s, loss=0.148, v_num=1, val_loss=0.0959, val_acc=0.974]\n",
            "Testing: 100% 79/79 [00:01<00:00, 41.44it/s]\n",
            "--------------------------------------------------------------------------------\n",
            "DATALOADER:0 TEST RESULTS\n",
            "{'test_acc': tensor(0.9736)}\n",
            "--------------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xq5ZQl8pxq5-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}